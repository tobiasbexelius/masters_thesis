In this chapter the methods used to implement and evaluate the product will be described.

\section{OpenCV}

OpenCV is an open source library for computer vision. 

\section{Preprocessing}

Preprocessing is the first step in computer vision algorithms. 
Its purpose here is to reduce noise. 
This is accomplished by converting the colour image to a grayscale image. 
Followed by applying a median filter. 
A median filter was chosen because it reduces noise effectively, while also removing small, unwanted features from the image, such as small labels and marks on the package or the rest of the scene. 
At the same time well defined edges are preserved.

\section{Edge detection}

The next step is to detect edges in the image. This is done using Canny's edge detection algorithm. As it is often a good pr


\section{Contour extraction}

To reduce amount of data contours are pruned by removing peripheral contours and short ones.

\section{Line detection}

Lines are detected by using the Hough Line Transform.

\section{Package Detection}

The algorithm used to detect the package is based on a ranking scheme, where multiple hypothesis about where the package is are created, and then scored. 
The candidate with the highest score is chosen as the package. 

A fundamental property of cuboids is exploited by the algorithm: they consist of parallel line segments of equal length. 
More specifically, the outline of a cuboid in a two dimensional image is made up of three pairs of parallel line segments, which form a hexagon. 
However because of perspective distortion the line segments will not be entirely parallel, and not  of exactly equal length.
This is where the ranking algorithm comes in.
The assumption that the package is the most symmetric hexagon in the image is made. % TODO not quite true, reformulate
Thus, the ranking algorithm rates a package candidate according to the degree of parallelism and equality of lengths between opposing sides.

The first step is, however, to find the candidates.
This is done by first finding pairs of parallel line segments. 
As mentioned above, the line segments will not be exactly parallel, due to perspective distortion. % TODO perspective distortion correct term? 
Thus a pair of line segments is considered to be parallel by the algorithm if the angle between them is below a threshold. 
This threshold is set to be high, to avoid discarding a pair that belongs to the actual package, since the perspective distortion is rather large from some perspectives. % TODO be more specific? example? max distortion?

The next step is to pick three pairs of parallel line segments and let their intersections form a polygon. 
Since the full contour of the package is not always distinguishable, the sought intersections are those between the lines (i. e. does not have a start or end point) defined by the line segments, not the line segments themselves. % elaborate, distinguishable from what? only some intersections are considered
The polygon is considered to be a candidate if it passes some basic tests, for example it must be convex and have six corners. 
The corner must also be within the bounds of the image.
Additionally, if the location of the reference object is known, the package must enclose the reference object.
This is done for all combinations of three parallel line pairs.
% Additional constraints... 

When all candidates are generated they are scored according to the rules rules presented above.

\section{Reference Object Detection}

The reference object is detected using a modified version of the package detection algorithm.
Since the reference object is a quadrilateral two pairs of parallel line segments are picked out at a time to form a quadrilateral.
The ranking algorithm also uses some additional criteria, since the reference object is a white ISO 216 A-series  paper, the score is also based on how bright the area within the polygon is, and how well the aspect ratio between the two sides matches that of a ISO 216 A-series paper.

\section{Measuring}

% TODO we only consider cases where three sides of the box is seen

The measuring is carried out in two steps, first the width and depth of the package are measured, followed by the height. The reason is that the top corners of the package are in the same plane as the reference object, of which we know the location in 3D-space.

Since the coordinates of the corners of the reference object is known in both image coordinates and world coordinates, a homography between the image plane and the top plane of the package (where the reference object is placed) can be calculated.

Using the homography, the top corners of the package, which are in the same plane as the reference object, can be projected into 3D space in the following fashion:

<Insert equation> % TODO

Now the width and depth of the package can be calculated by calculating the euclidean distance between the projected points.

A homography cannot be created in the same way between the image plane and one of the side planes of the package since, only two points are known in either of the side planes, in both image and world coordinates, i.e. the corners that lie in both the top, and side planes.

This is where the camera calibration is useful. 
Since the intrinsic parameters of the camera is known, along with some image-world point correspondences for the corners of the reference object, the pose of the camera can be estimated. 

TODO how is camera pose found?% TODO how is camera pose found?

Once the camera pose is known, the full camera matrix $P$ can be retrieved by multiplying the intrinsic and extrinsic matrices: $P = K[R|t]$ \cite[156]{hartley-zisserman}. 
As mentioned earlier mapping between 2D and 3D points can be done using the equation $x = PX$.
This equation can be expanded to the following form:
$$\begin{pmatrix} \tilde{u} \\ \tilde{v} \\ \tilde{w} \end{pmatrix} = \lambda
\begin{pmatrix} p_{11} & p_{12} & p_{13} & p_{14} \\
 				p_{21} & p_{22} & p_{23} & p_{24} \\
				p_{31} & p_{32} & p_{33} & p_{34} \end{pmatrix}
\begin{pmatrix}X \\Y \\Z \\1\end{pmatrix}$$
where $ \tilde{u}$, $\tilde{v}$, and $\tilde{w}$ are in homogeneous coordinates, and $\lambda$ is an arbitrary scale factor.
The scale factor is arbitrary because homogeneous coordinates are used.
$\tilde{u}$, $\tilde{v}$, and $\tilde{w}$ are all scaled by $\lambda$, and the cartesian image coordinates,  $u$ and $v$, are obtained by dividing by $\tilde{w}$:

$$u = \frac{\tilde{u}}{\tilde{w}}, v = \frac{\tilde{v}}{\tilde{w}}$$

And hence the scale factor disappears. By convention $\lambda = \frac{1}{p_{34}}$ which results in:

$$\begin{pmatrix} \tilde{u} \\ \tilde{v} \\ \tilde{w} \end{pmatrix} =
\begin{pmatrix} p_{11} & p_{12} & p_{13} & p_{14} \\
 				p_{21} & p_{22} & p_{23} & p_{24} \\
				p_{31} & p_{32} & p_{33} & 1 \end{pmatrix}
\begin{pmatrix}X \\Y \\Z \\1\end{pmatrix}$$
For convenience the scaling of the elements in $P$ is implicit.
This equation is useful because two of the lower corners of the package share $X$, and $Y$ coordinates with a top corner, which position in world coordinates is already known.
The image coordinates $(u,v)$ of one of the lower corners, and the world coordinates $(X,Y)$ of the corresponding upper corner can then be used to solve for $Z$. 
The above equation can be transformed to the following over-defined system:
$$
\begin{pmatrix} up_{33}-p_{13} \\ vp_{33}-p_{23} \end{pmatrix} Z = 
\begin{pmatrix}
X(p_{11}-up_{31}) + Y(p_{12}-up_{32})+p_{14}-u \\
X(p_{21}-vp_{31}) + Y(p_{22}-vp_{32})+p_{24}-v
\end{pmatrix}
$$
This least-squares problem is solved using SVD-decomposition. % Try QR decomposition
Since two pairs of upper-lower corners which share $X$ and $Y$ coordinates are known, two least-squares solutions of $Z$ can be obtained.
The solution with the smallest error is chosen as $Z$.




















