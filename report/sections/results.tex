\chapter{Results} \label{results}
The results are divided into four sections.
In section \ref{results:detection} the results of the detection algorithm are presented.
In section \ref{results:measuring} the results of the measuring algorithm are presented.
In section \ref{results:overall} the results of detection and measuring combined are presented.
Finally, in section \ref{results:online} the results of online testing are presented

\section{Detection} \label{results:detection}
The output of the detection algorithm was compared against ground truth positions of the reference object and package corners, as explained in \ref{benchmarking}.
The error was defined as the sum of distances between the detected points and actual points, divided by the length of the contour.
A detection result was considered to be correct if the error was less than $10\%$.
Table \ref{table:detection_overall} shows the success rates and average error of the detection algorithm on the set of 225 example image.

\input{floats/detection_overall}

Table \ref{table:detection_categories} shows the success rates of detection grouped by four categories: package, rotation, distance, and height. Table \ref{table:detection_categories_error} shows the average error grouped in the same way.

\input{floats/detection_categories}

\input{floats/detection_categories_error}

From table \ref{table:detection_categories} it can be concluded that the success rate of detection varied significantly between the entries in each category.
The frontal views yielded a much lower success rate than the other views.
The same can be said for the furthest distance, and the lowest height. 
From table \ref{table:detection_categories_error} it can be concluded that the relative error did not vary much.
The error was consistently lower for the package than the reference object. % TODO poorly chosen error metric, redo if time

\section{Measuring} \label{results:measuring} 
Measuring results were obtained by using ground truth positions of the corners as input to the measuring algorithm, and comparing the output against the real dimensions of the packages.
The error of each measurement was defined as the sum of relative errors of the three dimensions.
The error was measured as sum of relative errors.
A measurement was considered to be correct if no individual dimension of the package had a relative error greater than $10\%$.

Table \ref{table:measuring_overall} shows the success rate and average error of the two calibration methods.

\input{floats/measuring_overall} % TODO split error into x,y,z

Table \ref{table:measuring_categories} and \ref{table:measuring_categories_error} show the success rate and average error grouped in the same was as in the previous section.

\input{floats/measuring_categories}

\input{floats/measuring_categories_error}

The results in table \ref{table:measuring_categories} are somewhat similar to the corresponding detection results.
The two frontal views yielded lower success rates, especially for vanishing point calibration.
Success rates also decreased as distance increased.
Table \ref{table:measuring_categories_error} showed that the offline calibration method yielded slightly lower error than vanishing point calibration.

\section{Overall Performance} \label{results:overall}
The results in this section present the performance of the detection and measuring algorithms combined, using vanishing point calibration.
The errors are defined in the same way as in section \ref{results:measuring}.

Table \ref{table:overall_overall} shows the overall performance of detection and measuring combined.

\input{floats/overall_overall}

Table \ref{table:overall_categories} and \ref{table:overall_categories_error} show the success rate and average error of detection and measuring combined.

\input{floats/overall_categories}

\input{floats/overall_categories_error}

The results are similar to those of the individual parts, as expected.
The lower success rates of the frontal views, the furthest distance and the lowest height, are even more prominent in this case.
The results of disregarding these poorly performing positions and only considering the remaining positions are shown in table \ref{table:overall_good}.

\input{floats/overall_good}

Table \ref{table:overall_good} shows that disregarding a few of the positions results in a considerably better performance.

\section{Online testing} \label{results:online}

Online testing was performed using the Android application described in \ref{method:online_testing}.
A screenshot of the resulting application is shown in figure \ref{fig:screenshot}. % TODO add more screenshots
The processing time of the application was typically around 300 milliseconds at the resolution $800 \times 450$ on the Galaxy S6 Edge, depending on the amount of clutter in the image. 
More clutter resulted in higher processing times.

% 1000 ms at 1280x720

\begin{figure}[H]
\begin{center}
\includegraphics[width=0.6\textwidth]{figures/screenshot.png}
\end{center}
\caption{Screenshot of the app measuring package 2. A blue outline has been drawn around the package, and a red outline has been drawn around the reference object. The real dimensions of the package are $260 \times 191 \times 177$ mm.}
\label{fig:screenshot}
\end{figure}
